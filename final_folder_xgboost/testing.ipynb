{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-01 22:34:33,512] A new study created in memory with name: no-name-5a076df1-dc62-4660-88d3-c7140c9a5b72\n",
      "[I 2025-02-01 22:34:33,795] Trial 0 finished with value: 6863.990093232944 and parameters: {'max_depth': 7, 'learning_rate': 0.07048885540814713, 'n_estimators': 202, 'subsample': 0.757592098335327, 'colsample_bytree': 0.7533842900606312, 'reg_alpha': 0.032761328222110093, 'reg_lambda': 1.5999378469506238, 'gamma': 4.14483770476227}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:34,095] Trial 1 finished with value: 7598.4645817428145 and parameters: {'max_depth': 4, 'learning_rate': 0.1374873068178687, 'n_estimators': 384, 'subsample': 0.7687341437323257, 'colsample_bytree': 0.6795188587112315, 'reg_alpha': 1.1538795835627889, 'reg_lambda': 0.20876486228317762, 'gamma': 1.043731627841213}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:34,484] Trial 2 finished with value: 7270.7144078144065 and parameters: {'max_depth': 5, 'learning_rate': 0.09920621189557549, 'n_estimators': 345, 'subsample': 0.8543543829946144, 'colsample_bytree': 0.6858603948946316, 'reg_alpha': 1.2737346433435577, 'reg_lambda': 3.76616012152807, 'gamma': 4.8058092678671125}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:35,302] Trial 3 finished with value: 8893.489303979626 and parameters: {'max_depth': 9, 'learning_rate': 0.017621301798369637, 'n_estimators': 435, 'subsample': 0.8231136037814879, 'colsample_bytree': 0.6422568138981151, 'reg_alpha': 1.7425757461537086, 'reg_lambda': 0.6071629450516524, 'gamma': 4.285553793428355}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:35,756] Trial 4 finished with value: 9779.232280705884 and parameters: {'max_depth': 4, 'learning_rate': 0.016482022470890915, 'n_estimators': 586, 'subsample': 0.8859421862243944, 'colsample_bytree': 0.5935900983172191, 'reg_alpha': 0.015488968933491158, 'reg_lambda': 1.688259951379319, 'gamma': 1.0102207175924}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:36,405] Trial 5 finished with value: 8914.114650373305 and parameters: {'max_depth': 10, 'learning_rate': 0.11927458250350355, 'n_estimators': 377, 'subsample': 0.634239235797158, 'colsample_bytree': 0.5491844687608954, 'reg_alpha': 0.48695914679896835, 'reg_lambda': 1.0080478298040552, 'gamma': 3.6699518844346586}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:36,828] Trial 6 finished with value: 7812.141063754545 and parameters: {'max_depth': 5, 'learning_rate': 0.039137101915008195, 'n_estimators': 460, 'subsample': 0.8000076927573594, 'colsample_bytree': 0.5891259480331017, 'reg_alpha': 0.03260951403079584, 'reg_lambda': 2.2132151115157352, 'gamma': 1.7504666902118138}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:37,241] Trial 7 finished with value: 10881.250295807004 and parameters: {'max_depth': 5, 'learning_rate': 0.03388083984540786, 'n_estimators': 455, 'subsample': 0.8314642723371604, 'colsample_bytree': 0.5357579885149909, 'reg_alpha': 0.35753701672427474, 'reg_lambda': 2.762996863439359, 'gamma': 3.590887466671091}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:37,984] Trial 8 finished with value: 7125.556258987785 and parameters: {'max_depth': 9, 'learning_rate': 0.07293496347546741, 'n_estimators': 445, 'subsample': 0.6929686186738981, 'colsample_bytree': 0.6340843823831316, 'reg_alpha': 0.056340024911302786, 'reg_lambda': 1.087773763672166, 'gamma': 2.5919680281590383}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:38,499] Trial 9 finished with value: 8297.09684166697 and parameters: {'max_depth': 8, 'learning_rate': 0.011996876771573997, 'n_estimators': 325, 'subsample': 0.6208367776766673, 'colsample_bytree': 0.7849672075658378, 'reg_alpha': 0.0209758505212884, 'reg_lambda': 0.4101873725821928, 'gamma': 1.9731256838182543}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:38,801] Trial 10 finished with value: 7362.221675554194 and parameters: {'max_depth': 7, 'learning_rate': 0.19192632903800877, 'n_estimators': 207, 'subsample': 0.7152479702951244, 'colsample_bytree': 0.7945207334001836, 'reg_alpha': 0.09474782977497212, 'reg_lambda': 0.10593810998254556, 'gamma': 3.3021139714885224}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:39,088] Trial 11 finished with value: 7779.938817240146 and parameters: {'max_depth': 7, 'learning_rate': 0.06666990419253503, 'n_estimators': 200, 'subsample': 0.7145556868380023, 'colsample_bytree': 0.7082867704950149, 'reg_alpha': 0.06573412346980514, 'reg_lambda': 0.9724497734744685, 'gamma': 0.030375041758419652}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:39,925] Trial 12 finished with value: 7353.038827586864 and parameters: {'max_depth': 8, 'learning_rate': 0.06780520672032063, 'n_estimators': 535, 'subsample': 0.6847484215488591, 'colsample_bytree': 0.745464804967751, 'reg_alpha': 0.05661665613827308, 'reg_lambda': 1.290952207695232, 'gamma': 2.8947485174624394}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:40,434] Trial 13 finished with value: 7590.710902148758 and parameters: {'max_depth': 10, 'learning_rate': 0.06036638818265039, 'n_estimators': 257, 'subsample': 0.6709313161392587, 'colsample_bytree': 0.6236834421442352, 'reg_alpha': 0.21597709508882512, 'reg_lambda': 0.4976973632663655, 'gamma': 2.369066618500691}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:40,881] Trial 14 finished with value: 6913.06994033765 and parameters: {'max_depth': 8, 'learning_rate': 0.0320148247919059, 'n_estimators': 289, 'subsample': 0.7586484632397006, 'colsample_bytree': 0.7394939830911921, 'reg_alpha': 0.03495992391621139, 'reg_lambda': 4.564211008376259, 'gamma': 4.319345703150699}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:41,220] Trial 15 finished with value: 7387.777202921052 and parameters: {'max_depth': 6, 'learning_rate': 0.02589836028509365, 'n_estimators': 278, 'subsample': 0.7536762230529019, 'colsample_bytree': 0.7414653539324345, 'reg_alpha': 0.026912505631944177, 'reg_lambda': 4.950684417975816, 'gamma': 4.7546915852832985}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:41,644] Trial 16 finished with value: 7090.140760238826 and parameters: {'max_depth': 8, 'learning_rate': 0.027940881041562567, 'n_estimators': 257, 'subsample': 0.7852921404926463, 'colsample_bytree': 0.7565864222916524, 'reg_alpha': 0.0138641903791101, 'reg_lambda': 2.9453975511198167, 'gamma': 4.300940280164248}. Best is trial 0 with value: 6863.990093232944.\n",
      "[I 2025-02-01 22:34:41,992] Trial 17 finished with value: 6847.647187173125 and parameters: {'max_depth': 6, 'learning_rate': 0.0525553465840302, 'n_estimators': 288, 'subsample': 0.7363733515175679, 'colsample_bytree': 0.7184042892781647, 'reg_alpha': 0.010894599627222983, 'reg_lambda': 4.806232062333126, 'gamma': 4.151126830060006}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:42,276] Trial 18 finished with value: 8121.545173179793 and parameters: {'max_depth': 6, 'learning_rate': 0.052898431404782294, 'n_estimators': 229, 'subsample': 0.7273760145237328, 'colsample_bytree': 0.7038660981122951, 'reg_alpha': 0.012240696296257299, 'reg_lambda': 1.7540210400936063, 'gamma': 3.8950371710027643}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:42,638] Trial 19 finished with value: 7209.130322029142 and parameters: {'max_depth': 6, 'learning_rate': 0.08711307170829258, 'n_estimators': 307, 'subsample': 0.6487062898853346, 'colsample_bytree': 0.6717784468018131, 'reg_alpha': 0.1625155311239406, 'reg_lambda': 0.2804130617926481, 'gamma': 3.069316504949809}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:42,979] Trial 20 finished with value: 6886.370887484932 and parameters: {'max_depth': 7, 'learning_rate': 0.04750739772169637, 'n_estimators': 240, 'subsample': 0.7348146512807134, 'colsample_bytree': 0.7174270214946108, 'reg_alpha': 0.011804050380905415, 'reg_lambda': 2.9911697967647304, 'gamma': 4.949425633204519}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:43,318] Trial 21 finished with value: 6902.084322869433 and parameters: {'max_depth': 7, 'learning_rate': 0.0472022533448901, 'n_estimators': 239, 'subsample': 0.7334973284577033, 'colsample_bytree': 0.7168426576288985, 'reg_alpha': 0.010774172040055686, 'reg_lambda': 3.127346088924122, 'gamma': 4.863138429816047}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:43,705] Trial 22 finished with value: 6894.273275697737 and parameters: {'max_depth': 6, 'learning_rate': 0.043951351211256005, 'n_estimators': 338, 'subsample': 0.7809279525274433, 'colsample_bytree': 0.7732665107951758, 'reg_alpha': 0.0212783743360647, 'reg_lambda': 2.32161088935517, 'gamma': 4.0246302173369335}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:44,196] Trial 23 finished with value: 6946.69907222128 and parameters: {'max_depth': 7, 'learning_rate': 0.0835152524005361, 'n_estimators': 274, 'subsample': 0.7440496557487415, 'colsample_bytree': 0.7249192345306403, 'reg_alpha': 0.03988358345207958, 'reg_lambda': 1.6252217811085028, 'gamma': 4.96082078560055}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:44,486] Trial 24 finished with value: 7024.283023910697 and parameters: {'max_depth': 6, 'learning_rate': 0.05279840760670775, 'n_estimators': 220, 'subsample': 0.6998964312778384, 'colsample_bytree': 0.7657143802151646, 'reg_alpha': 0.010378511480599675, 'reg_lambda': 3.8229832958256544, 'gamma': 4.440224917863954}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:44,942] Trial 25 finished with value: 7053.691232255634 and parameters: {'max_depth': 7, 'learning_rate': 0.1105621904772783, 'n_estimators': 247, 'subsample': 0.801552404711217, 'colsample_bytree': 0.6598289889470998, 'reg_alpha': 0.01703440801747032, 'reg_lambda': 2.1796815313420708, 'gamma': 3.4149931698134823}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:45,244] Trial 26 finished with value: 9620.175050382399 and parameters: {'max_depth': 5, 'learning_rate': 0.022764461792430198, 'n_estimators': 301, 'subsample': 0.660352704207545, 'colsample_bytree': 0.6908089954855487, 'reg_alpha': 0.02301724406878804, 'reg_lambda': 3.87636211821225, 'gamma': 3.9368810608008378}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:45,647] Trial 27 finished with value: 7454.473287899018 and parameters: {'max_depth': 9, 'learning_rate': 0.1569735888495523, 'n_estimators': 201, 'subsample': 0.7155354903889963, 'colsample_bytree': 0.7250898803615103, 'reg_alpha': 0.0960779982645027, 'reg_lambda': 0.8464446230832885, 'gamma': 4.701295694309122}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:46,105] Trial 28 finished with value: 11591.258085298592 and parameters: {'max_depth': 7, 'learning_rate': 0.039100420398136715, 'n_estimators': 360, 'subsample': 0.6058276026428183, 'colsample_bytree': 0.5034416395993984, 'reg_alpha': 0.042832387079205274, 'reg_lambda': 1.4672278663525753, 'gamma': 4.479946531470983}. Best is trial 17 with value: 6847.647187173125.\n",
      "[I 2025-02-01 22:34:46,419] Trial 29 finished with value: 8452.02366300521 and parameters: {'max_depth': 4, 'learning_rate': 0.0568308824635528, 'n_estimators': 399, 'subsample': 0.7747921317912205, 'colsample_bytree': 0.6652172384742655, 'reg_alpha': 0.017124440783027526, 'reg_lambda': 2.7926864323862413, 'gamma': 3.8119313244573796}. Best is trial 17 with value: 6847.647187173125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 RMSE: 8133.165681332208\n",
      "Model 2 RMSE: 8203.996587030008\n",
      "Model 3 RMSE: 8025.477182074596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "### Load training and scoring data\n",
    "df = pd.read_csv(\"final_train.csv\", index_col=0)\n",
    "df1 = pd.read_csv(\"final_score.csv\", index_col=0)\n",
    "\n",
    "categorical_cols = [\"Vehicle Category\", \"Fuel Type\", \"Fuel Technology\", \"Electric Mile Range\"]\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"Preprocesses the dataset by handling missing values, encoding categorical variables, and dropping unnecessary columns.\"\"\"\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df.drop(columns=\"Region\", axis=1)\n",
    "    df = df.dropna(subset=[\"Model Year\"]).sort_values(\"Model Year\").reset_index(drop=True)\n",
    "    df[\"Model Year\"] = df[\"Model Year\"].astype(int)\n",
    "\n",
    "    # Convert categorical columns to category type\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    # Encode categorical columns\n",
    "    df[\"Number of Vehicles Registered at the Same Address\"] = df[\"Number of Vehicles Registered at the Same Address\"].replace(\n",
    "        {'1': 1, '2': 2, '3': 3, \"≥4\": 4, \"Unknown\": -1})\n",
    "\n",
    "    # Replace unknown values in GVWR Class column\n",
    "    df[\"GVWR Class\"] = df[\"GVWR Class\"].replace({\"Not Applicable\": -1, \"Unknown\": -1})\n",
    "    return df\n",
    "\n",
    "df = preprocess(df)\n",
    "df1 = preprocess(df1)\n",
    "\n",
    "# Split the train data (df) into training and testing sets\n",
    "X = df.drop(columns=\"Vehicle Population\")\n",
    "y = df[\"Vehicle Population\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert GVWR Class to categorical type\n",
    "X_train[\"GVWR Class\"] = X_train[\"GVWR Class\"].astype(\"category\").cat.codes\n",
    "X_test[\"GVWR Class\"] = X_test[\"GVWR Class\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Separate features and target variable for scoring data\n",
    "X_scoring = df1.drop(columns=\"Vehicle Population\", errors=\"ignore\")\n",
    "y_scoring = df1[\"Vehicle Population\"] if \"Vehicle Population\" in df1 else None\n",
    "\n",
    "# Convert GVWR Class to categorical type\n",
    "X_scoring[\"GVWR Class\"] = X_scoring[\"GVWR Class\"].astype(\"category\").cat.codes\n",
    "\n",
    "### Hyperparameter tuning function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 0.9),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.8),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 2.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.1, 5.0),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.0, 5.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    encoder = TargetEncoder(cols=categorical_cols)\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "    X_train_encoded[categorical_cols] = encoder.fit_transform(X_train[categorical_cols], y_train)\n",
    "    X_test_encoded[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Run Optuna tuning\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Save models with the best parameters\n",
    "top_trials = sorted(study.trials, key=lambda x: x.value)[:3]\n",
    "top_params = [trial.params for trial in top_trials]\n",
    "\n",
    "with open(\"final_params.json\", \"w\") as f:\n",
    "    json.dump(top_params, f, indent=4)\n",
    "\n",
    "# Load best models' parameters and apply to scoring dataset\n",
    "with open(\"final_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "encoder = TargetEncoder(cols=categorical_cols)\n",
    "X_train_encoded = X_train.copy()\n",
    "X_train_encoded[categorical_cols] = encoder.fit_transform(X_train[categorical_cols], y_train)\n",
    "scoring_encoded = X_scoring.copy()\n",
    "scoring_encoded[categorical_cols] = encoder.transform(X_scoring[categorical_cols])\n",
    "\n",
    "# Prediction with best models\n",
    "predictions = {}\n",
    "rmse_scores = {}\n",
    "\n",
    "for i, params in enumerate(best_params):\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(scoring_encoded)\n",
    "    predictions[f\"Model_{i+1}\"] = y_pred\n",
    "\n",
    "    if y_scoring is not None:\n",
    "        rmse = np.sqrt(mean_squared_error(y_scoring, y_pred))\n",
    "        rmse_scores[f\"Model_{i+1}\"] = rmse\n",
    "        print(f\"Model {i+1} RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
