{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-01 15:17:24,626] A new study created in memory with name: no-name-ce754264-2a4b-4bd7-849f-6959954df601\n",
      "[I 2025-02-01 15:17:24,782] Trial 0 finished with value: 15986.497302411182 and parameters: {'max_depth': 5, 'learning_rate': 0.03479121980879509, 'n_estimators': 133, 'subsample': 0.894184831407942, 'colsample_bytree': 0.6293554536118854, 'colsample_bylevel': 0.5762194699112217, 'colsample_bynode': 0.6019341134791701, 'reg_alpha': 0.05958191772908269, 'reg_lambda': 0.5469249925291472, 'gamma': 3.663134771040312}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:25,375] Trial 1 finished with value: 16628.052441581967 and parameters: {'max_depth': 8, 'learning_rate': 0.042274777100556674, 'n_estimators': 335, 'subsample': 0.8694405785135927, 'colsample_bytree': 0.6759663828350396, 'colsample_bylevel': 0.7749043629232928, 'colsample_bynode': 0.697355720158363, 'reg_alpha': 0.14483210504730717, 'reg_lambda': 4.490776502825333, 'gamma': 4.762168770671028}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:26,077] Trial 2 finished with value: 16258.055972347986 and parameters: {'max_depth': 8, 'learning_rate': 0.0405218580030466, 'n_estimators': 440, 'subsample': 0.6564476029017828, 'colsample_bytree': 0.6268318764296612, 'colsample_bylevel': 0.6180270241306395, 'colsample_bynode': 0.6237149680714846, 'reg_alpha': 1.8481039344908923, 'reg_lambda': 3.8561773367263084, 'gamma': 0.04375317896023301}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:26,390] Trial 3 finished with value: 16091.634099742636 and parameters: {'max_depth': 8, 'learning_rate': 0.029668997091919204, 'n_estimators': 183, 'subsample': 0.600393939342016, 'colsample_bytree': 0.602136584302094, 'colsample_bylevel': 0.5811627759391184, 'colsample_bynode': 0.6490437019927263, 'reg_alpha': 0.014609403618445692, 'reg_lambda': 3.077476896017008, 'gamma': 4.935697757127573}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:26,679] Trial 4 finished with value: 16307.225392444909 and parameters: {'max_depth': 3, 'learning_rate': 0.13633258517728586, 'n_estimators': 394, 'subsample': 0.7938915371959012, 'colsample_bytree': 0.5037940856737623, 'colsample_bylevel': 0.6654995006646622, 'colsample_bynode': 0.5078955577221481, 'reg_alpha': 0.01131430839368672, 'reg_lambda': 0.7053728385181566, 'gamma': 4.328481645604288}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:26,788] Trial 5 finished with value: 15994.580082015282 and parameters: {'max_depth': 3, 'learning_rate': 0.052420636232203395, 'n_estimators': 147, 'subsample': 0.6328176262774748, 'colsample_bytree': 0.6330918387690802, 'colsample_bylevel': 0.7422686401510894, 'colsample_bynode': 0.5210312971366438, 'reg_alpha': 0.03977561340744183, 'reg_lambda': 3.320288402922263, 'gamma': 4.094807400879844}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:27,200] Trial 6 finished with value: 17535.67700432464 and parameters: {'max_depth': 5, 'learning_rate': 0.08142155968820614, 'n_estimators': 417, 'subsample': 0.7527660531137822, 'colsample_bytree': 0.5420355505706117, 'colsample_bylevel': 0.792231368051733, 'colsample_bynode': 0.6131915350709383, 'reg_alpha': 0.11891926389596713, 'reg_lambda': 0.2223742408312955, 'gamma': 0.2513929517945046}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:27,318] Trial 7 finished with value: 16155.571670479507 and parameters: {'max_depth': 4, 'learning_rate': 0.06661912590070763, 'n_estimators': 125, 'subsample': 0.8487812850222742, 'colsample_bytree': 0.7639815839582484, 'colsample_bylevel': 0.7922133841038594, 'colsample_bynode': 0.5980393004972673, 'reg_alpha': 0.039297070598137876, 'reg_lambda': 0.17526624789952944, 'gamma': 4.986291569687732}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:27,787] Trial 8 finished with value: 16583.606362911538 and parameters: {'max_depth': 8, 'learning_rate': 0.05449131718575941, 'n_estimators': 310, 'subsample': 0.882968448319562, 'colsample_bytree': 0.5977836151414889, 'colsample_bylevel': 0.6996861354514065, 'colsample_bynode': 0.6620237206860937, 'reg_alpha': 0.23471450202772973, 'reg_lambda': 2.414286927363209, 'gamma': 3.7369227702242336}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:27,967] Trial 9 finished with value: 16055.549570164205 and parameters: {'max_depth': 5, 'learning_rate': 0.043983184176327156, 'n_estimators': 176, 'subsample': 0.8385679760296201, 'colsample_bytree': 0.7097143044784807, 'colsample_bylevel': 0.58563761026293, 'colsample_bynode': 0.6034544741995673, 'reg_alpha': 0.11934029017223839, 'reg_lambda': 0.2841803379651128, 'gamma': 0.7273237831105372}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:28,289] Trial 10 finished with value: 16135.150696538289 and parameters: {'max_depth': 6, 'learning_rate': 0.0211375644557452, 'n_estimators': 251, 'subsample': 0.6994307118555847, 'colsample_bytree': 0.798096995630544, 'colsample_bylevel': 0.5439343821734421, 'colsample_bynode': 0.7969445535313361, 'reg_alpha': 0.6507404197177349, 'reg_lambda': 0.8317325826972791, 'gamma': 2.8157770357067933}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:28,391] Trial 11 finished with value: 16108.323810999082 and parameters: {'max_depth': 3, 'learning_rate': 0.09324204629013635, 'n_estimators': 119, 'subsample': 0.701653181015052, 'colsample_bytree': 0.6786326578545671, 'colsample_bylevel': 0.5007695903050182, 'colsample_bynode': 0.5079053767168965, 'reg_alpha': 0.037843704596415666, 'reg_lambda': 0.9952655914173387, 'gamma': 3.2134550185113726}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:28,680] Trial 12 finished with value: 16183.578343493753 and parameters: {'max_depth': 6, 'learning_rate': 0.029201692771309115, 'n_estimators': 237, 'subsample': 0.6212997596047515, 'colsample_bytree': 0.5831120160415438, 'colsample_bylevel': 0.7243458610611899, 'colsample_bynode': 0.5508295825721661, 'reg_alpha': 0.04182244436706733, 'reg_lambda': 0.4827985620132828, 'gamma': 1.885473582749573}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:28,864] Trial 13 finished with value: 16369.039556430915 and parameters: {'max_depth': 4, 'learning_rate': 0.18128053247630035, 'n_estimators': 199, 'subsample': 0.7983840829543959, 'colsample_bytree': 0.6412506130537535, 'colsample_bylevel': 0.6596074059423773, 'colsample_bynode': 0.555431298338007, 'reg_alpha': 0.024247130373332405, 'reg_lambda': 1.444441960669444, 'gamma': 3.790529337025352}. Best is trial 0 with value: 15986.497302411182.\n",
      "[I 2025-02-01 15:17:28,975] Trial 14 finished with value: 15982.691137602578 and parameters: {'max_depth': 4, 'learning_rate': 0.027175742370149338, 'n_estimators': 107, 'subsample': 0.717550646193783, 'colsample_bytree': 0.7180987688299713, 'colsample_bylevel': 0.7056728572635853, 'colsample_bynode': 0.5588740279713417, 'reg_alpha': 0.06433605726183311, 'reg_lambda': 0.41693065829042963, 'gamma': 2.07448835494728}. Best is trial 14 with value: 15982.691137602578.\n",
      "[I 2025-02-01 15:17:29,414] Trial 15 finished with value: 15995.683417722421 and parameters: {'max_depth': 4, 'learning_rate': 0.02127853584121774, 'n_estimators': 487, 'subsample': 0.7274866399859181, 'colsample_bytree': 0.7300605673348941, 'colsample_bylevel': 0.6263110387178293, 'colsample_bynode': 0.7008313814767798, 'reg_alpha': 0.07352997873645731, 'reg_lambda': 0.39608604839923583, 'gamma': 1.8295007399147178}. Best is trial 14 with value: 15982.691137602578.\n",
      "[I 2025-02-01 15:17:29,543] Trial 16 finished with value: 16050.358749884688 and parameters: {'max_depth': 5, 'learning_rate': 0.027274248988031578, 'n_estimators': 107, 'subsample': 0.7885918244570482, 'colsample_bytree': 0.7233315815080256, 'colsample_bylevel': 0.6950028541743632, 'colsample_bynode': 0.565653821502096, 'reg_alpha': 0.32228349800399353, 'reg_lambda': 0.11777273446889622, 'gamma': 1.927107514033283}. Best is trial 14 with value: 15982.691137602578.\n",
      "[I 2025-02-01 15:17:30,184] Trial 17 finished with value: 16483.89565606383 and parameters: {'max_depth': 7, 'learning_rate': 0.032365414267229164, 'n_estimators': 261, 'subsample': 0.754337834811704, 'colsample_bytree': 0.6796231975666154, 'colsample_bylevel': 0.5559674178703596, 'colsample_bynode': 0.7615024586727952, 'reg_alpha': 0.08185606966140915, 'reg_lambda': 0.4915912748154636, 'gamma': 2.571660266948479}. Best is trial 14 with value: 15982.691137602578.\n",
      "[I 2025-02-01 15:17:30,395] Trial 18 finished with value: 16060.2196747118 and parameters: {'max_depth': 4, 'learning_rate': 0.03486252054814574, 'n_estimators': 220, 'subsample': 0.6806639584943004, 'colsample_bytree': 0.5693482017194452, 'colsample_bylevel': 0.6073833203346332, 'colsample_bynode': 0.5749350056574473, 'reg_alpha': 0.01937408449615532, 'reg_lambda': 1.7481625845989488, 'gamma': 1.2413776114441788}. Best is trial 14 with value: 15982.691137602578.\n",
      "[I 2025-02-01 15:17:30,642] Trial 19 finished with value: 16015.203776411963 and parameters: {'max_depth': 6, 'learning_rate': 0.024620578201914826, 'n_estimators': 161, 'subsample': 0.898437090080631, 'colsample_bytree': 0.7534688080465188, 'colsample_bylevel': 0.5178647754113401, 'colsample_bynode': 0.6526238356322864, 'reg_alpha': 0.40171158736141827, 'reg_lambda': 0.308340273351485, 'gamma': 3.1388712039649134}. Best is trial 14 with value: 15982.691137602578.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 RMSE: 19235.836555762267\n",
      "Model 2 RMSE: 19464.514584237644\n",
      "Model 3 RMSE: 19208.947914969212\n",
      "\n",
      "âœ… Final Checks Passed. No Index Errors. Model is Ready!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Load cleaned dataset, ensuring 'Unnamed: 0' is removed if present\n",
    "df = pd.read_csv(\"cleaned_data.csv\", index_col=0)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "df = df.drop(columns=[\"Region\"], errors=\"ignore\")  # Drop 'Region' if it exists\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = [\"Vehicle Category\", \"Fuel Type\", \"Fuel Technology\", \"Electric Mile Range\"]\n",
    "numerical_cols = [\"GVWR Class\", \"Number of Vehicles Registered at the Same Address\"]\n",
    "\n",
    "# Convert categorical columns to category type\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "\n",
    "# Handle categorical replacements for ordinal columns\n",
    "df[\"Number of Vehicles Registered at the Same Address\"] = df[\"Number of Vehicles Registered at the Same Address\"].replace(\n",
    "    {'1': 1, '2': 2, '3': 3, \"\\u22654\": 4, \"Unknown\": -1}\n",
    ")\n",
    "df[\"GVWR Class\"] = df[\"GVWR Class\"].replace({\"Not Applicable\": -1, \"Unknown\": -1})\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"Vehicle Population\"], errors=\"ignore\")\n",
    "y = df[\"Vehicle Population\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure 'GVWR Class' is encoded properly\n",
    "X_train[\"GVWR Class\"] = X_train[\"GVWR Class\"].astype(\"category\").cat.codes.astype(\"int64\")\n",
    "X_test[\"GVWR Class\"] = X_test[\"GVWR Class\"].astype(\"category\").cat.codes.astype(\"int64\")\n",
    "\n",
    "# Encoding categorical features\n",
    "encoder = TargetEncoder(cols=categorical_cols)\n",
    "\n",
    "X_train_encoded = X_train.copy().reset_index(drop=True)\n",
    "X_train_encoded[categorical_cols] = encoder.fit_transform(X_train[categorical_cols], y_train)\n",
    "\n",
    "X_test_encoded = X_test.copy().reset_index(drop=True)\n",
    "X_test_encoded[categorical_cols] = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Ensure no NaNs exist after encoding\n",
    "X_test_encoded[categorical_cols] = X_test_encoded[categorical_cols].fillna(X_train_encoded[categorical_cols].mean())\n",
    "\n",
    "# Ensure numerical columns match training data types\n",
    "for col in numerical_cols:\n",
    "    if col in X_test_encoded.columns:\n",
    "        X_test_encoded[col] = X_test_encoded[col].astype(X_train_encoded[col].dtype)\n",
    "\n",
    "# Hyperparameter tuning using Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.02, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 0.9),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.8),\n",
    "        'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 0.8),\n",
    "        'colsample_bynode': trial.suggest_uniform('colsample_bynode', 0.5, 0.8),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 2.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.1, 5.0),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.0, 5.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Save the best hyperparameters\n",
    "top_trials = sorted(study.trials, key=lambda x: x.value)[:3]\n",
    "top_params = [trial.params for trial in top_trials]\n",
    "\n",
    "with open(\"best_models.json\", \"w\") as f:\n",
    "    json.dump(top_params, f, indent=4)\n",
    "\n",
    "# Load best models for final prediction\n",
    "with open(\"best_models.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# Load new dataset for final scoring\n",
    "scoring_data = pd.read_csv(\"scoring_cleaned_data.csv\", index_col=0)\n",
    "\n",
    "# Drop 'Unnamed: 0' if it exists\n",
    "scoring_data = scoring_data.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "\n",
    "# Ensure categorical columns exist\n",
    "missing_cols = [col for col in categorical_cols if col not in scoring_data.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing categorical columns in scoring dataset: {missing_cols}\")\n",
    "\n",
    "# Prepare features for scoring\n",
    "X_scoring = scoring_data.drop(columns=[\"Vehicle Population\"], errors=\"ignore\")\n",
    "y_scoring = scoring_data[\"Vehicle Population\"] if \"Vehicle Population\" in scoring_data else None\n",
    "\n",
    "# Apply encoding using the same trained encoder\n",
    "X_scoring = X_scoring.reset_index(drop=True)  # Reset index before encoding\n",
    "scoring_encoded = X_scoring.copy()\n",
    "\n",
    "# Encode categorical columns safely\n",
    "encoded_cats = encoder.transform(X_scoring[categorical_cols]).reset_index(drop=True)\n",
    "\n",
    "# Assign transformed categorical features back safely\n",
    "for col in categorical_cols:\n",
    "    scoring_encoded[col] = encoded_cats[col]\n",
    "\n",
    "# Ensure numerical columns match training set types\n",
    "for col in numerical_cols:\n",
    "    if col in scoring_encoded.columns:\n",
    "        scoring_encoded[col] = scoring_encoded[col].astype(X_train_encoded[col].dtype)\n",
    "\n",
    "# ðŸ”¥ Fix: Ensure `scoring_encoded` has the same columns as `X_train_encoded`\n",
    "missing_features = set(X_train_encoded.columns) - set(scoring_encoded.columns)\n",
    "extra_features = set(scoring_encoded.columns) - set(X_train_encoded.columns)\n",
    "\n",
    "# Add missing features if necessary (e.g., \"Date\")\n",
    "for feature in missing_features:\n",
    "    scoring_encoded[feature] = X_train_encoded[feature].mean()  # Fill missing feature with mean value\n",
    "\n",
    "# Drop extra features not in training data\n",
    "for feature in extra_features:\n",
    "    scoring_encoded = scoring_encoded.drop(columns=[feature])\n",
    "\n",
    "# Ensure column order matches training data\n",
    "scoring_encoded = scoring_encoded[X_train_encoded.columns]\n",
    "\n",
    "# Train models on best hyperparameters and predict\n",
    "rmse_scores = {}\n",
    "predictions = {}\n",
    "\n",
    "for i, params in enumerate(best_params):\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(scoring_encoded)\n",
    "    predictions[f\"Model_{i+1}\"] = y_pred\n",
    "\n",
    "    if y_scoring is not None:\n",
    "        rmse = np.sqrt(mean_squared_error(y_scoring, y_pred))\n",
    "        rmse_scores[f\"Model_{i+1}\"] = rmse\n",
    "        print(f\"Model {i+1} RMSE: {rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
